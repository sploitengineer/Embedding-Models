#!/usr/bin/env python

import os
import requests
import json
import mysql.connector
import numpy as np
import faiss
from mysql.connector import Error

# ------------------ CONFIGURATION ------------------
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "YOUR_OPENAI_API_KEY")  # Replace with your key or set an env variable.
OPENAI_EMBEDDING_URL = "https://api.openai.com/v1/embeddings"
EMBEDDING_MODEL = "text-embedding-ada-002"

# MySQL connection info
MYSQL_CONFIG = {
    'host': 'localhost',
    'user': 'your_mysql_user',
    'password': 'your_mysql_password',
    'database': 'your_database_name'
}
TABLE_NAME = "test_cases"

# FAISS similarity threshold (cosine similarity in [0,1])
SIMILARITY_THRESHOLD = 0.7
# Number of top matches to retrieve
TOP_K = 3

# ------------------ HELPER FUNCTIONS ------------------

def create_connection():
    """Create and return a MySQL database connection."""
    try:
        connection = mysql.connector.connect(**MYSQL_CONFIG)
        if connection.is_connected():
            return connection
    except Error as e:
        print("Error connecting to MySQL:", e)
    return None

def fetch_test_cases():
    """
    Fetch all test cases from the MySQL table.
    Expects columns: id, user_story, acceptance_criteria.
    """
    conn = create_connection()
    records = []
    if conn:
        try:
            cursor = conn.cursor(dictionary=True)
            query = f"SELECT id, user_story, acceptance_criteria FROM {TABLE_NAME}"
            cursor.execute(query)
            records = cursor.fetchall()
            print(f"Fetched {len(records)} test cases from the database.")
        except Error as e:
            print("Error fetching data:", e)
        finally:
            cursor.close()
            conn.close()
    return records

def combine_text(record):
    """Combine user_story and acceptance_criteria into one string."""
    return f"User Story: {record['user_story']} Acceptance Criteria: {record['acceptance_criteria']}"

def call_openai_embedding_api(text):
    """
    Call OpenAI's text-embedding-ada-002 API for a single text input.
    Returns a NumPy float32 embedding vector.
    """
    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {OPENAI_API_KEY}"
    }
    data = {
        "model": EMBEDDING_MODEL,
        "input": text
    }
    response = requests.post(OPENAI_EMBEDDING_URL, headers=headers, data=json.dumps(data))
    
    if response.status_code == 200:
        result = response.json()
        embedding = result["data"][0]["embedding"]
        return np.array(embedding, dtype=np.float32)
    else:
        print(f"OpenAI API request failed: {response.status_code}, {response.text}")
        return None

def build_faiss_index(embeddings, dimension):
    """
    Build a FAISS HNSW index for the given embeddings.
    We use inner product as a proxy for cosine similarity (after normalization).
    """
    # Normalize embeddings to unit length so that inner product = cosine similarity.
    faiss.normalize_L2(embeddings)
    
    # Build an HNSW index (efficient approximate nearest neighbor search).
    index = faiss.IndexHNSWFlat(dimension, 32, faiss.METRIC_INNER_PRODUCT)
    index.hnsw.efConstruction = 40
    index.add(embeddings)
    return index

def search_faiss(index, query_vector, k=TOP_K):
    """
    Search the FAISS index for the top-k similar embeddings.
    Returns (scores, indices).
    """
    # Convert to the correct shape
    query_vector = np.array([query_vector], dtype=np.float32)
    # Normalize
    faiss.normalize_L2(query_vector)
    distances, indices = index.search(query_vector, k)
    return distances[0], indices[0]

# ------------------ MAIN PIPELINE ------------------

def main():
    # Step 1: Fetch records from MySQL.
    records = fetch_test_cases()
    if not records:
        print("No records found. Exiting.")
        return
    
    # Step 2: Embed each record and store in memory.
    #         We'll build arrays: embeddings and metadata (IDs + original text).
    embeddings = []
    metadata = []
    print("Embedding records with OpenAI API...")
    for rec in records:
        text = combine_text(rec)
        emb = call_openai_embedding_api(text)
        if emb is None:
            # If embedding fails, skip this record or handle differently.
            continue
        embeddings.append(emb)
        metadata.append({
            "id": rec["id"],
            "user_story": rec["user_story"],
            "acceptance_criteria": rec["acceptance_criteria"],
            "combined": text
        })
    
    embeddings = np.array(embeddings, dtype=np.float32)
    dimension = embeddings.shape[1]
    print(f"Successfully embedded {len(embeddings)} records.")
    
    # Step 3: Build a FAISS index using these embeddings.
    print("Building FAISS index...")
    index = build_faiss_index(embeddings, dimension)
    
    # Step 4: Prompt user for a new test case, embed it, and search for similar records.
    print("\nEnter new test case details (input can be incomplete):")
    new_user_story = input("New User Story: ").strip()
    new_acceptance_criteria = input("New Acceptance Criteria: ").strip()
    
    new_text = f"User Story: {new_user_story} Acceptance Criteria: {new_acceptance_criteria}"
    query_emb = call_openai_embedding_api(new_text)
    if query_emb is None:
        print("Failed to embed the new input. Exiting.")
        return
    
    # Step 5: Search the FAISS index.
    distances, indices = search_faiss(index, query_emb, k=TOP_K)
    
    print("\nMatching stored test cases using text-embedding-ada-002 + FAISS (HNSW):\n")
    matches_found = False
    for score, idx in zip(distances, indices):
        # 'score' is in [0,1] for cosine similarity if embeddings are normalized.
        if score >= SIMILARITY_THRESHOLD:
            matches_found = True
            rec = metadata[idx]
            print(f"Match Found (Cosine Similarity: {score:.4f})")
            print(f"ID: {rec['id']}")
            print(f"User Story: {rec['user_story']}")
            print(f"Acceptance Criteria: {rec['acceptance_criteria']}\n")
    
    if not matches_found:
        print("No matches found above the similarity threshold.")

if __name__ == "__main__":
    main()
